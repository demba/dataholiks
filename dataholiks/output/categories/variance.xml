<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>DataHoliks (Variance)</title><link>http://dataholiks.com/</link><description></description><atom:link href="http://dataholiks.com/categories/variance.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Mon, 18 Jan 2016 07:08:47 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>The Sample Mean Revisited</title><link>http://dataholiks.com/posts/the-sample-mean-revisited.html</link><dc:creator>Sourav Dey</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="The-Sample-Mean-Revisited"&gt;The Sample Mean Revisited&lt;a class="anchor-link" href="http://dataholiks.com/posts/the-sample-mean-revisited.html#The-Sample-Mean-Revisited"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I think statistics is taught wrongly at most universities. It is taught as if computers were never invented. Now that was fine 100 years ago. Even 20 years ago. But now computation is dirt cheap — and there is a better way to learn statistics — through Monte Carlo simulation.  For example, the sample mean is one of the first things you learn in a statistics class.  You learn about the standard error of the sample mean and how it scales as: $$\sigma/\sqrt{N}.$$&lt;/p&gt;
&lt;p&gt;And you do some algebra and take it at face value.  But with Monte Carlo simulation you don’t have to take it at face value. You can simulate sampling, the sample mean, and see what distribution it has.  That’s what the following Python code does.&lt;/p&gt;
&lt;p&gt;It’s very straight forward. I assume that I take Ns independent samples from a zero-mean, unit variance Gaussian distribution. I then compute the sample mean: $$\sum x_i/N_s .$$&lt;/p&gt;
&lt;p&gt;I do this 30,000 times for three different Ns: $$N_s = 2, 4, 16.$$&lt;/p&gt;
&lt;p&gt;The histograms of the sample means are plotted below.  As expected, the variance of the sample mean is less when you have more samples.  The distribution is narrower around the true mean (zero in this case).  The theoretical sampling distribution, with mean zero and : 
$$ standard\ deviation = standard\ error = \sigma/\sqrt{N}.$$&lt;/p&gt;
&lt;p&gt;is plotted as well.&lt;/p&gt;
&lt;p&gt;Writing this code yourself and seeing the distributions match the theory goes way further than doing any sort of algebraic manipulation to make statistics real in my mind.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="http://dataholiks.com/posts/the-sample-mean-revisited.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>mathjax</category><category>Monte Carlo Methods</category><category>Sample Mean</category><category>Simulation</category><category>Variance</category><guid>http://dataholiks.com/posts/the-sample-mean-revisited.html</guid><pubDate>Sat, 25 Jul 2015 19:46:54 GMT</pubDate></item></channel></rss>